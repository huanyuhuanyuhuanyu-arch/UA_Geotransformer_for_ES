{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-89_bM2rWDne"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Setup (run once per fresh Colab runtime)\n",
        "# ============================================================\n",
        "!pip -q install \\\n",
        "  rasterio==1.3.8 geopandas==0.14.0 shap==0.45.0 xgboost==2.0.3 \\\n",
        "  scikit-learn==1.5.0 matplotlib==3.8.4 pandas==2.2.2 tqdm==4.66.4 \\\n",
        "  scipy==1.11.4 pyogrio==0.9.0 pyproj==3.6.1 rtree==1.2.0 \\\n",
        "  torch==2.3.0 torchvision==0.18.0 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
        "\n",
        "# ============================================================\n",
        "# Imports\n",
        "# ============================================================\n",
        "import os, json, numpy as np, pandas as pd, geopandas as gpd, matplotlib.pyplot as plt\n",
        "import rasterio, rasterio.mask\n",
        "from rasterio.enums import Resampling\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from xgboost import XGBClassifier\n",
        "import shap\n",
        "from scipy.spatial import cKDTree\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ============================================================\n",
        "# A) Suitability — sample generator (with extra negatives)\n",
        "# ============================================================\n",
        "raster_files = {\n",
        "    \"elevation\": \"elevation.tif\",\n",
        "    \"slope\": \"slope.tif\",\n",
        "    \"aspect\": \"aspect.tif\",\n",
        "    \"runoff\": \"runoff.tif\",\n",
        "    \"distance_water\": \"distance_water.tif\",\n",
        "    \"distance_road\": \"distance_road.tif\",\n",
        "    \"distance_rail\": \"distance_rail.tif\",\n",
        "    \"wetland\": \"wetland.tif\",\n",
        "    \"pop_density\": \"pop_density.tif\",\n",
        "    \"ecoreserve\": \"ecoreserve.tif\"\n",
        "}\n",
        "rasters = {k: rasterio.open(v) for k, v in raster_files.items()}\n",
        "ref_raster = rasters[\"slope\"]; W, H = ref_raster.width, ref_raster.height; transform = ref_raster.transform\n",
        "\n",
        "def score_pixel(vals):\n",
        "    score = 0\n",
        "    def safe(v): return v if -1e10 < v < 1e10 else np.nan\n",
        "    if safe(vals[\"distance_water\"]) < 500: score += 1\n",
        "    if safe(vals[\"slope\"]) < 5: score += 1\n",
        "    if safe(vals[\"runoff\"]) > 4: score += 1\n",
        "    if safe(vals[\"pop_density\"]) > 25: score += 1\n",
        "    if safe(vals[\"distance_road\"]) < 500: score += 1\n",
        "    if safe(vals[\"distance_rail\"]) < 1000: score += 1\n",
        "    if safe(vals[\"distance_water\"]) > 2000: score -= 1\n",
        "    if safe(vals[\"slope\"]) > 15: score -= 1\n",
        "    if safe(vals[\"runoff\"]) < 1: score -= 1\n",
        "    if safe(vals[\"pop_density\"]) < 5: score -= 1\n",
        "    if safe(vals[\"distance_road\"]) > 3000: score -= 1\n",
        "    if vals[\"ecoreserve\"] == 1: score -= 1\n",
        "    return score\n",
        "\n",
        "np.random.seed(42); target_per_class = 200; max_attempts = 100000\n",
        "class_1, class_0, neutral = [], [], []\n",
        "with tqdm(total=max_attempts) as pbar:\n",
        "    while len(class_1)<target_per_class or len(class_0)<target_per_class or len(neutral)<target_per_class:\n",
        "        row, col = np.random.randint(0,H), np.random.randint(0,W)\n",
        "        x,y = rasterio.transform.xy(transform, row, col)\n",
        "        vals, valid = {}, True\n",
        "        for name, r in rasters.items():\n",
        "            try:\n",
        "                v = list(r.sample([(x,y)]))[0][0]\n",
        "                if v in [-9999,-99999] or np.isnan(v): valid=False; break\n",
        "                vals[name]=v\n",
        "            except: valid=False; break\n",
        "        if not valid: pbar.update(1); continue\n",
        "        s = score_pixel(vals)\n",
        "        if s>=3 and len(class_1)<target_per_class: class_1.append((x,y,1,*vals.values()))\n",
        "        elif s<=-1 and len(class_0)<target_per_class: class_0.append((x,y,0,*vals.values()))\n",
        "        elif -1<s<3 and len(neutral)<target_per_class: neutral.append((x,y,0,*vals.values()))\n",
        "        pbar.update(1);\n",
        "        if pbar.n>=max_attempts: break\n",
        "\n",
        "final_class_0 = class_0 + neutral[:(target_per_class-len(class_0))]\n",
        "final_data = class_1 + final_class_0\n",
        "df_samples = pd.DataFrame(final_data, columns=[\"x\",\"y\",\"label\"]+list(raster_files.keys()))\n",
        "df_samples.to_csv(\"samples.csv\", index=False)\n",
        "print(\"✅ samples.csv saved:\", df_samples.shape)\n",
        "\n",
        "# ============================================================\n",
        "# B) XGBoost + SHAP on points (baseline LR/RF comparison)\n",
        "# ============================================================\n",
        "samples = pd.read_csv(\"samples.csv\")\n",
        "drivers = list(raster_files.keys())\n",
        "def extract_raster_values(sample_df, tif_list):\n",
        "    feats=[]\n",
        "    for f in tif_list:\n",
        "        with rasterio.open(f) as src:\n",
        "            vals = [list(src.sample([(x,y)]))[0][0] for x,y in zip(sample_df.x, sample_df.y)]\n",
        "            feats.append(vals)\n",
        "    arr = np.array(feats).T\n",
        "    return pd.DataFrame(arr, columns=[os.path.splitext(os.path.basename(f))[0] for f in tif_list])\n",
        "\n",
        "X = extract_raster_values(samples, [f\"{k}.tif\" for k in drivers])\n",
        "y = samples[\"label\"]\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "xgb_points = XGBClassifier()\n",
        "xgb_points.fit(X_train,y_train)\n",
        "print(\"Train acc:\", xgb_points.score(X_train,y_train), \" Test acc:\", xgb_points.score(X_test,y_test))\n",
        "\n",
        "# Baselines\n",
        "def eval_model(model, X, y):\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    aucs, prs = [], []\n",
        "    for tr,te in cv.split(X,y):\n",
        "        model.fit(X.iloc[tr], y.iloc[tr])\n",
        "        p = model.predict_proba(X.iloc[te])[:,1]\n",
        "        aucs.append(roc_auc_score(y.iloc[te], p))\n",
        "        prs.append(average_precision_score(y.iloc[te], p))\n",
        "    return np.mean(aucs), np.mean(prs)\n",
        "\n",
        "lr_auc, lr_pr = eval_model(LogisticRegression(max_iter=200, class_weight=\"balanced\", solver=\"liblinear\"), X, y)\n",
        "rf_auc, rf_pr = eval_model(RandomForestClassifier(n_estimators=500,n_jobs=-1,class_weight=\"balanced\",random_state=42), X, y)\n",
        "xgb_auc, xgb_pr = eval_model(XGBClassifier(), X, y)\n",
        "pd.DataFrame({\"model\":[\"XGBoost\",\"Logistic\",\"RandomForest\"],\"AUC\":[xgb_auc,lr_auc,rf_auc],\"PR-AUC\":[xgb_pr,lr_pr,rf_pr]}).to_csv(\"/content/baseline_comparison.csv\", index=False)\n",
        "\n",
        "# SHAP\n",
        "expl = shap.Explainer(xgb_points); sv = expl(X)\n",
        "shap.summary_plot(sv, X, show=False); plt.show()\n",
        "shap.plots.bar(sv, max_display=10, show=False); plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# C) Align rasters to reference slope.tif -> /content/aligned\n",
        "# ============================================================\n",
        "input_dir = \"/content\"; aligned_dir = \"/content/aligned\"; os.makedirs(aligned_dir, exist_ok=True)\n",
        "ref_file = os.path.join(input_dir, \"slope.tif\")\n",
        "with rasterio.open(ref_file) as ref:\n",
        "    ref_profile, ref_transform, ref_crs = ref.profile, ref.transform, ref.crs\n",
        "    ref_shape = (ref.height, ref.width)\n",
        "\n",
        "for fname in os.listdir(input_dir):\n",
        "    if not fname.endswith(\".tif\"): continue\n",
        "    src_path = os.path.join(input_dir,fname); dst_path=os.path.join(aligned_dir,fname)\n",
        "    with rasterio.open(src_path) as src:\n",
        "        data = src.read(out_shape=(src.count, ref_shape[0], ref_shape[1]), resampling=Resampling.bilinear)\n",
        "        profile = src.profile\n",
        "        profile.update(height=ref_shape[0], width=ref_shape[1], transform=ref_transform, crs=ref_crs)\n",
        "        with rasterio.open(dst_path,\"w\",**profile) as dst: dst.write(data)\n",
        "print(\"✅ Aligned → /content/aligned\")\n",
        "\n",
        "# ============================================================\n",
        "# D) Suitability mapping on aligned rasters + IDW fill + 4 outputs\n",
        "# ============================================================\n",
        "raster_root = aligned_dir\n",
        "study_shp = \"/content/study_area.shp\"\n",
        "raster_files_map = {\n",
        "    \"elevation\":\"elevation.tif\",\"slope\":\"slope.tif\",\"aspect\":\"aspect.tif\",\n",
        "    \"runoff\":\"runoff.tif\",\"distance_water\":\"distance_water.tif\",\n",
        "    \"distance_road\":\"distance_road.tif\",\"distance_rail\":\"distance_rail.tif\",\n",
        "    \"wetland\":\"wetland.tif\",\"pop_density\":\"pop_density.tif\",\"ecoreserve\":\"ecoreserve.tif\"\n",
        "}\n",
        "def score_balanced(vals):\n",
        "    score=0\n",
        "    def safe(v): return v if -1e10 < v < 1e10 else np.nan\n",
        "    if safe(vals[\"distance_water\"])<400: score+=1\n",
        "    if safe(vals[\"slope\"])<6: score+=1\n",
        "    if safe(vals[\"runoff\"])>4: score+=1\n",
        "    if safe(vals[\"pop_density\"])>20: score+=1\n",
        "    if safe(vals[\"distance_road\"])<700: score+=1\n",
        "    if safe(vals[\"distance_rail\"])<1200: score+=1\n",
        "    if safe(vals[\"distance_water\"])>2500: score-=1\n",
        "    if safe(vals[\"slope\"])>12: score-=1\n",
        "    if safe(vals[\"runoff\"])<1: score-=1\n",
        "    if safe(vals[\"pop_density\"])<8: score-=1\n",
        "    if safe(vals[\"distance_road\"])>3500: score-=1\n",
        "    if vals[\"ecoreserve\"]==1: score-=1\n",
        "    return score\n",
        "\n",
        "# sample for training\n",
        "ras_map = {k:rasterio.open(os.path.join(raster_root,v)) for k,v in raster_files_map.items()}\n",
        "ref = ras_map[\"slope\"]; W,H = ref.width, ref.height; transform = ref.transform\n",
        "np.random.seed(42); pos,neg=[],[]\n",
        "with tqdm(total=200000) as pbar:\n",
        "    while len(pos)<300 or len(neg)<300:\n",
        "        row, col = np.random.randint(0,H), np.random.randint(0,W)\n",
        "        x,y = rasterio.transform.xy(transform,row,col)\n",
        "        vals, valid = {}, True\n",
        "        for name,r in ras_map.items():\n",
        "            try:\n",
        "                v = list(r.sample([(x,y)]))[0][0]\n",
        "                if v in [-9999,-99999] or np.isnan(v): valid=False; break\n",
        "                vals[name]=v\n",
        "            except: valid=False; break\n",
        "        if not valid: pbar.update(1); continue\n",
        "        s = score_balanced(vals)\n",
        "        if s>=4 and len(pos)<300: pos.append((x,y,1,*vals.values()))\n",
        "        elif s<=1 and len(neg)<300: neg.append((x,y,0,*vals.values()))\n",
        "        pbar.update(1)\n",
        "        if pbar.n>=200000: break\n",
        "\n",
        "cols = list(raster_files_map.keys())\n",
        "df_map = pd.DataFrame(pos+neg, columns=[\"x\",\"y\",\"label\"]+cols)\n",
        "X_map, y_map = df_map[cols], df_map[\"label\"]\n",
        "xgb_map = XGBClassifier(n_estimators=100,max_depth=4,learning_rate=0.05,subsample=0.8,colsample_bytree=0.8,eval_metric=\"logloss\").fit(X_map,y_map)\n",
        "\n",
        "# predict full map\n",
        "stacked=[]; profile=None\n",
        "for f in raster_files_map.values():\n",
        "    with rasterio.open(os.path.join(raster_root,f)) as src:\n",
        "        stacked.append(src.read(1))\n",
        "        if profile is None: profile=src.profile\n",
        "stacked = np.stack(stacked,axis=-1)\n",
        "flat = stacked.reshape(-1, len(cols))\n",
        "valid_mask = ~np.any(np.isnan(flat),axis=1)\n",
        "pred = np.full(flat.shape[0], np.nan)\n",
        "pred[valid_mask] = xgb_map.predict_proba(flat[valid_mask])[:,1]\n",
        "suitability_full = pred.reshape((H,W))\n",
        "\n",
        "# mask to AOI\n",
        "gdf = gpd.read_file(study_shp)\n",
        "with rasterio.open(os.path.join(raster_root,\"slope.tif\")) as src:\n",
        "    out_img,_ = rasterio.mask.mask(src, gdf.geometry, crop=False)\n",
        "    study_mask = out_img[0] != src.nodata\n",
        "suitability_masked = np.where(study_mask, suitability_full, np.nan)\n",
        "\n",
        "# IDW fill\n",
        "def idw_fill(raster, mask, power=2, k=8):\n",
        "    filled = raster.copy()\n",
        "    rows, cols = np.where(~np.isnan(raster))\n",
        "    if len(rows)==0: return raster\n",
        "    known_coords = np.c_[rows,cols]; known_vals = raster[rows,cols]\n",
        "    t_rows, t_cols = np.where(mask)\n",
        "    if len(t_rows)==0: return raster\n",
        "    target_coords = np.c_[t_rows,t_cols]\n",
        "    tree = cKDTree(known_coords)\n",
        "    dists, idxs = tree.query(target_coords, k=k)\n",
        "    weights = 1 / (dists**power + 1e-12); weights /= weights.sum(axis=1, keepdims=True)\n",
        "    interp = (weights * known_vals[idxs]).sum(axis=1)\n",
        "    filled[t_rows, t_cols] = interp\n",
        "    return filled\n",
        "\n",
        "idw_mask = np.isnan(suitability_masked) & study_mask\n",
        "suitability_filled = idw_fill(suitability_masked, idw_mask)\n",
        "\n",
        "def save_tif(arr, path, profile):\n",
        "    profile.update(dtype=rasterio.float32, count=1)\n",
        "    with rasterio.open(path,\"w\",**profile) as dst: dst.write(arr.astype(np.float32),1)\n",
        "\n",
        "full_map  = suitability_filled\n",
        "high_map  = np.where(full_map>=0.7, full_map, np.nan)\n",
        "mid_map   = np.where((full_map>=0.3)&(full_map<0.7), full_map, np.nan)\n",
        "low_map   = np.where((full_map>0)&(full_map<0.3), full_map, np.nan)\n",
        "\n",
        "save_tif(full_map, \"/content/ua_suitability_full.tif\", profile)\n",
        "save_tif(high_map, \"/content/ua_suitability_high.tif\", profile)\n",
        "save_tif(mid_map,  \"/content/ua_suitability_medium.tif\", profile)\n",
        "save_tif(low_map,  \"/content/ua_suitability_low.tif\", profile)\n",
        "\n",
        "plt.figure(figsize=(8,5)); plt.imshow(full_map,cmap=\"YlGn\",vmin=0,vmax=1)\n",
        "plt.title(\"Urban Agriculture Suitability Map (IDW-Filled)\"); plt.axis(\"off\"); plt.colorbar(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# E) Unconstrained scenario (MLP): 2010→2017 training → simulate 2030 & 2050\n",
        "# ============================================================\n",
        "rroot = aligned_dir\n",
        "landuse_2010 = f\"{rroot}/2010_9.tif\"\n",
        "landuse_2017 = f\"{rroot}/2017_9.tif\"\n",
        "study_shp = \"/content/study_area.shp\"\n",
        "suitability_map = f\"{rroot}/suitability.tif\"  # optional\n",
        "\n",
        "def read_r(path):\n",
        "    with rasterio.open(path) as src: return src.read(1), src.profile\n",
        "\n",
        "def list_drivers():\n",
        "    exclude = {\"2010_9.tif\",\"2017_9.tif\",\"simulated_landuse_2030.tif\",\"simulated_landuse_2050.tif\",\"suitability.tif\"}\n",
        "    return [f for f in os.listdir(rroot) if f.endswith(\".tif\") and f not in exclude]\n",
        "\n",
        "def load_mask(shp_path, ref_raster_path):\n",
        "    gdf = gpd.read_file(shp_path)\n",
        "    with rasterio.open(ref_raster_path) as src:\n",
        "        out, _ = rasterio.mask.mask(src, gdf.geometry, crop=False, filled=False)\n",
        "        return out[0].astype(bool)\n",
        "\n",
        "def prepare_X_y(landuse_t1, landuse_t2):\n",
        "    mask = load_mask(study_shp, landuse_t1)\n",
        "    y1,_ = read_r(landuse_t1); y2,_ = read_r(landuse_t2)\n",
        "    drivers=[]\n",
        "    for fname in sorted(list_drivers()):\n",
        "        d,_ = read_r(os.path.join(rroot,fname)); drivers.append(d)\n",
        "    if os.path.exists(suitability_map):\n",
        "        s,_ = read_r(suitability_map); drivers.append(s)\n",
        "    X = np.stack(drivers,axis=-1)\n",
        "    valid = np.all(~np.isnan(X),axis=-1) & ~np.isnan(y1) & ~np.isnan(y2) & mask\n",
        "    X = X[valid]; y = y2[valid].astype(int)\n",
        "    y = LabelEncoder().fit_transform(y)\n",
        "    X = MinMaxScaler().fit_transform(X)\n",
        "    return X, y, drivers, mask\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self,in_dim,out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(in_dim,64), nn.ReLU(),\n",
        "                                 nn.Linear(64,64), nn.ReLU(),\n",
        "                                 nn.Linear(64,out_dim))\n",
        "    def forward(self,x): return self.net(x)\n",
        "\n",
        "class RDataset(Dataset):\n",
        "    def __init__(self,X,y): self.X=torch.tensor(X,dtype=torch.float32); self.y=torch.tensor(y,dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self,i): return self.X[i], self.y[i]\n",
        "\n",
        "def train_once(X,y):\n",
        "    in_dim=X.shape[1]; out_dim=len(np.unique(y))\n",
        "    cw=torch.tensor(compute_class_weight(\"balanced\",classes=np.unique(y),y=y),dtype=torch.float32)\n",
        "    model=MLP(in_dim,out_dim); opt=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "    loss_fn=nn.CrossEntropyLoss(weight=cw); loader=DataLoader(RDataset(X,y),batch_size=512,shuffle=True)\n",
        "    for epoch in range(20):\n",
        "        for bx,by in loader:\n",
        "            logits=model(bx); loss=loss_fn(logits,by)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "    return model\n",
        "\n",
        "def simulate(model, drivers, ref_path, out_path, lock_class=0):\n",
        "    full_stack=np.stack(drivers,axis=-1); flat=full_stack.reshape(-1,full_stack.shape[-1])\n",
        "    valid_mask = np.all(~np.isnan(flat),axis=-1); flat_valid = (flat[valid_mask]-flat[valid_mask].min(0))/(flat[valid_mask].ptp(0)+1e-9)\n",
        "    with torch.no_grad():\n",
        "        logits=model(torch.tensor(flat_valid,dtype=torch.float32))\n",
        "        preds = torch.softmax(logits,dim=1).argmax(1).numpy()\n",
        "    corrected=np.full(flat.shape[0],np.nan); corrected[valid_mask]=preds\n",
        "    ref_map,_ = read_r(landuse_2010); ref_flat=ref_map.flatten(); corrected[ref_flat==lock_class]=lock_class\n",
        "    out_arr=corrected.reshape(full_stack.shape[:-1])\n",
        "    with rasterio.open(ref_path) as ref:\n",
        "        profile=ref.profile; profile.update(dtype=rasterio.uint8,count=1)\n",
        "        with rasterio.open(out_path,\"w\",**profile) as dst: dst.write(out_arr.astype(np.uint8),1)\n",
        "    return out_arr\n",
        "\n",
        "# Train on 2010→2017, simulate 2030\n",
        "X1,y1,drivers1,_ = prepare_X_y(landuse_2010, landuse_2017)\n",
        "model_2030 = train_once(X1,y1)\n",
        "ref = rasterio.open(landuse_2010)\n",
        "sim2030 = simulate(model_2030, drivers1, landuse_2010, f\"{rroot}/simulated_landuse_2030.tif\")\n",
        "\n",
        "# Train on 2017→sim2030, simulate 2050\n",
        "X2,y2,drivers2,_ = prepare_X_y(landuse_2017, f\"{rroot}/simulated_landuse_2030.tif\")\n",
        "model_2050 = train_once(X2,y2)\n",
        "sim2050 = simulate(model_2050, drivers2, landuse_2010, f\"{rroot}/simulated_landuse_2050.tif\")\n",
        "\n",
        "plt.imshow(sim2050, cmap=\"tab20\"); plt.title(\"Unconstrained Scenario — 2050\"); plt.axis(\"off\"); plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# F) Landscape-method scenario (growth constraints; class-0 lock)\n",
        "#     Training pairs also updated to 2010→2017 then 2017→2030\n",
        "# ============================================================\n",
        "def simulate_future(model, drivers, ref_path, base_map, out_path, base_ref):\n",
        "    full_stack=np.stack(drivers,axis=-1); flat=full_stack.reshape(-1,full_stack.shape[-1])\n",
        "    valid_mask=np.all(~np.isnan(flat),axis=-1); flat_valid=(flat[valid_mask]-flat[valid_mask].min(0))/(flat[valid_mask].ptp(0)+1e-9)\n",
        "    with torch.no_grad():\n",
        "        logits=model(torch.tensor(flat_valid,dtype=torch.float32))\n",
        "        preds=torch.softmax(logits,dim=1).argmax(1).numpy()\n",
        "    corrected=np.full(flat.shape[0],np.nan); corrected[valid_mask]=preds\n",
        "    base_flat=base_map.flatten(); ref_flat=base_ref.flatten(); corrected[ref_flat==0]=0\n",
        "    for cls in range(1,10):\n",
        "        ref_count=np.sum(ref_flat==cls); pred_idx=np.where(corrected==cls)[0]\n",
        "        if cls in [1,2]:   min_n=ref_count+1;      max_n=ref_count*1.10\n",
        "        elif cls in [4,5]: min_n=ref_count+1;      max_n=ref_count*1.05\n",
        "        elif cls==9:       min_n=ref_count*0.80;   max_n=ref_count*0.90\n",
        "        else:              min_n=ref_count*0.95;   max_n=ref_count*1.05\n",
        "        cur=len(pred_idx)\n",
        "        if cur>max_n:\n",
        "            drop=int(cur-max_n); corrected[pred_idx[:drop]]=base_flat[pred_idx[:drop]]\n",
        "        elif cur<min_n:\n",
        "            alt=np.where((corrected!=cls)&(ref_flat!=0))[0]; fill=int(min_n-cur); corrected[alt[:fill]]=cls\n",
        "    out_arr=corrected.reshape(full_stack.shape[:-1])\n",
        "    with rasterio.open(ref_path) as ref:\n",
        "        profile=ref.profile; profile.update(dtype=rasterio.uint8,count=1)\n",
        "        with rasterio.open(out_path,\"w\",**profile) as dst: dst.write(out_arr.astype(np.uint8),1)\n",
        "    return out_arr\n",
        "\n",
        "# 2010→2017 train → simulate 2030 (constrained)\n",
        "X1_l,y1_l,drivers1_l,_ = prepare_X_y(landuse_2010, landuse_2017)\n",
        "model_2030_l = train_once(X1_l,y1_l)\n",
        "base_map_2017,_ = read_r(landuse_2017); base_ref,_ = read_r(landuse_2010)\n",
        "sim2030_l = simulate_future(model_2030_l, drivers1_l, landuse_2010, base_map_2017, f\"{rroot}/simulated_landuse_2030.tif\", base_ref)\n",
        "\n",
        "# 2017→2030 train → simulate 2050 (constrained)\n",
        "X2_l,y2_l,drivers2_l,_ = prepare_X_y(landuse_2017, f\"{rroot}/simulated_landuse_2030.tif\")\n",
        "model_2050_l = train_once(X2_l,y2_l)\n",
        "base_map_2030,_ = read_r(f\"{rroot}/simulated_landuse_2030.tif\")\n",
        "sim2050_l = simulate_future(model_2050_l, drivers2_l, landuse_2010, base_map_2030, f\"{rroot}/simulated_landuse_2050.tif\", base_ref)\n",
        "\n",
        "plt.imshow(sim2050_l, cmap=\"tab20\"); plt.title(\"Landscape-Method Scenario — 2050\"); plt.axis(\"off\"); plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# G) BAU baseline via transition matrices\n",
        "#     Updated to 2010→2017 matrix; forecast 2030 & 2050\n",
        "# ============================================================\n",
        "rroot_bau = \"/content/\"  # <- note: this baseline reads from /content/\n",
        "landuse_2010_b = f\"{rroot_bau}/2010_9.tif\"\n",
        "landuse_2017_b = f\"{rroot_bau}/2017_9.tif\"\n",
        "study_shp_b = \"study_area.shp\"\n",
        "\n",
        "def read_b(p):\n",
        "    with rasterio.open(p) as src: return src.read(1), src.profile\n",
        "def load_mask_b(shp, ref_r):\n",
        "    gdf=gpd.read_file(shp);\n",
        "    with rasterio.open(ref_r) as src: out,_=rasterio.mask.mask(src,gdf.geometry,crop=False);\n",
        "    return out[0].astype(bool)\n",
        "def save_b(arr,path,profile):\n",
        "    profile.update(dtype=rasterio.uint8,count=1)\n",
        "    with rasterio.open(path,\"w\",**profile) as dst: dst.write(arr.astype(np.uint8),1)\n",
        "def trans_matrix(a,b,mask):\n",
        "    a=a[:mask.shape[0],:mask.shape[1]].astype(int); b=b[:mask.shape[0],:mask.shape[1]].astype(int)\n",
        "    valid = mask & (~np.isnan(a)) & (~np.isnan(b))\n",
        "    M=np.zeros((10,10))\n",
        "    for i in range(10):\n",
        "        from_idx=(a==i)&valid; total=np.sum(from_idx)\n",
        "        if total==0: continue\n",
        "        for j in range(10): M[i,j]=np.sum((b==j)&from_idx)/total\n",
        "    return M\n",
        "def simulate_by_M(cur, M, mask, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    cur=cur[:mask.shape[0],:mask.shape[1]].astype(int); nxt=cur.copy()\n",
        "    R,C=cur.shape\n",
        "    for r in tqdm(range(R)):\n",
        "        for c in range(C):\n",
        "            if not mask[r,c]: continue\n",
        "            cl=int(cur[r,c])\n",
        "            if cl==0: nxt[r,c]=0\n",
        "            elif 0<=cl<10: nxt[r,c]=np.random.choice(np.arange(10), p=M[cl])\n",
        "            else: nxt[r,c]=cl\n",
        "    return nxt\n",
        "\n",
        "ref_map, profile_b = read_b(landuse_2010_b)\n",
        "land2017,_ = read_b(landuse_2017_b)\n",
        "mask_b = load_mask_b(study_shp_b, landuse_2010_b)\n",
        "M_10_17 = trans_matrix(ref_map, land2017, mask_b)\n",
        "print(\"✅ Transition matrix 2010→2017 computed\")\n",
        "\n",
        "sim2030_b = simulate_by_M(land2017, M_10_17, mask_b, seed=123)\n",
        "save_b(sim2030_b, f\"{rroot_bau}/simulated_landuse_2030.tif\", profile_b)\n",
        "\n",
        "M_17_30 = trans_matrix(land2017, sim2030_b, mask_b)\n",
        "sim2050_b = simulate_by_M(sim2030_b, M_17_30, mask_b, seed=456)\n",
        "save_b(sim2050_b, f\"{rroot_bau}/simulated_landuse_2050.tif\", profile_b)\n",
        "\n",
        "print(\"✅ BAU 2030/2050 exported.\")\n"
      ]
    }
  ]
}